{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8901593d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load library and configuration parameters\n",
    "#Denoising autoencoder\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils as utils\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.autograd import Variable\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from tqdm import tqdm\n",
    "import scipy.io as sio\n",
    "\n",
    "import os\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d2baa131",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classes\n",
    "\n",
    "# Target dataset\n",
    "class CustomDataset(Dataset):\n",
    "\n",
    "    def __init__(self, only_train=True):\n",
    "        \n",
    "        target_path = '../11-Video_Feature_Generation/'\n",
    "        data_meta = pd.read_csv(target_path +'output/scaled_objects/meta_data.csv')      \n",
    "        self.data = []\n",
    "        if only_train:\n",
    "            n = data_meta[data_meta['test_train']=='test'].index[0]\n",
    "        else:\n",
    "            n = len(data_meta)\n",
    "        # read all data \n",
    "        for i in range(0, n):\n",
    "            img_path = target_path + data_meta.loc[i, 'scaled_im_path'][2:]\n",
    "            class_name = data_meta.loc[i, 'name']\n",
    "            self.data.append([img_path, class_name])\n",
    "        # read class types\n",
    "        tmp = data_meta[['name','class']].drop_duplicates().sort_values(by='class').reset_index(drop=True)\n",
    "        class_map_ = dict()\n",
    "        for i in range(0, len(tmp)):\n",
    "            name_ = tmp.loc[i, 'name']\n",
    "            class_ = int(tmp.loc[i, 'class'])\n",
    "            class_map_[name_] = class_\n",
    "        self.class_map = class_map_\n",
    "        self.img_dim = (64, 64)\n",
    "        \n",
    "    def __len__(self):\n",
    "        \n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img_path, class_name = self.data[idx]\n",
    "        # read\n",
    "        img = cv2.imread(img_path)\n",
    "        # convert to grayscale\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        # resize\n",
    "        img = cv2.resize(img, self.img_dim)\n",
    "        # normalize\n",
    "        img = img/255.0\n",
    "        # cast to float\n",
    "        img = img.astype('float32')\n",
    "        # expan dim\n",
    "        img = np.expand_dims(img, axis=0)\n",
    "        \n",
    "        class_id = self.class_map[class_name]\n",
    "        img_tensor = torch.from_numpy(img)\n",
    "        #img_tensor = img_tensor.permute(2, 0, 1)\n",
    "        class_id = torch.tensor([class_id])\n",
    "        \n",
    "        return img_tensor, class_id\n",
    "    \n",
    "# Encoder settings\n",
    "class Encoder(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        \n",
    "        super(Encoder,self).__init__()\n",
    "        \n",
    "        self.conv1=nn.Sequential(\n",
    "            nn.Conv2d(1, 64, 3, 1, 1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.LeakyReLU(0.2)\n",
    "        )\n",
    "        \n",
    "        self.maxpool1 = nn.MaxPool2d(2, stride=2, return_indices=True)\n",
    "        \n",
    "        self.conv2 = nn.Sequential(\n",
    "            torch.nn.Conv2d(64, 50, 3, 1, 1),  \n",
    "            torch.nn.BatchNorm2d(50),\n",
    "            torch.nn.LeakyReLU(0.2))\n",
    "        \n",
    "        self.maxpool2 = nn.MaxPool2d(2, stride=2, return_indices=True)\n",
    "        \n",
    "        self.conv3 = nn.Sequential(\n",
    "            torch.nn.Conv2d(50, 36, 3, 1, 1),\n",
    "            torch.nn.BatchNorm2d(36),\n",
    "            torch.nn.LeakyReLU(0.2))\n",
    "        \n",
    "        self.maxpool3 = nn.MaxPool2d(2, stride=2, return_indices=True)\n",
    "        \n",
    "        self.conv4 = nn.Sequential(\n",
    "            torch.nn.Conv2d(36,22, 3, 1, 1),  \n",
    "            torch.nn.BatchNorm2d(22),\n",
    "            torch.nn.LeakyReLU(0.2))\n",
    "        \n",
    "        self.maxpool4 = nn.MaxPool2d(2, stride=2, return_indices=True)\n",
    "        \n",
    "        self.conv5 = nn.Sequential(\n",
    "            torch.nn.Conv2d(22, 8, 3, 1, 1),\n",
    "            torch.nn.BatchNorm2d(8),\n",
    "            torch.nn.Sigmoid())\n",
    "        \n",
    "        self.maxpool5 = nn.MaxPool2d(2, stride=2, return_indices=True)\n",
    "        \n",
    "    def forward(self, x_in):\n",
    "        \n",
    "        x = self.conv1(x_in)\n",
    "        x , indices1 = self.maxpool1(x)\n",
    "        x = self.conv2(x)\n",
    "        x , indices2 = self.maxpool2(x)\n",
    "        x = self.conv3(x)\n",
    "        x , indices3 = self.maxpool3(x)\n",
    "        x = self.conv4(x)\n",
    "        x , indices4 = self.maxpool4(x)\n",
    "        x = self.conv5(x)\n",
    "        feature , indices5 = self.maxpool5(x)\n",
    "        \n",
    "        indices = [indices1, indices2, indices3, indices4, indices5]\n",
    "        \n",
    "        return feature, indices\n",
    "    \n",
    "# Decoder settings\n",
    "class Decoder(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        \n",
    "        super(Decoder,self).__init__()\n",
    "        \n",
    "        self.convtrans1 = nn.Sequential(nn.ConvTranspose2d(8, 22, 3, 1, 1), )\n",
    "        \n",
    "        self.maxunpool1= nn.MaxUnpool2d(2, stride=2)\n",
    "        \n",
    "        self.convtrans2 = nn.Sequential(nn.ConvTranspose2d(22, 36, 3, 1, 1), )\n",
    "        \n",
    "        self.maxunpool2 = nn.MaxUnpool2d(2,stride=2)\n",
    "        \n",
    "        self.convtrans3 = nn.Sequential(nn.ConvTranspose2d(36, 50, 3, 1, 1), )\n",
    "        \n",
    "        self.maxunpool3 = nn.MaxUnpool2d(2, stride=2)\n",
    "        \n",
    "        self.convtrans4 = nn.Sequential(nn.ConvTranspose2d(50, 64, 3, 1, 1), )\n",
    "        \n",
    "        self.maxunpool4 = nn.MaxUnpool2d(2,stride=2)\n",
    "        \n",
    "        self.convtrans5 = nn.Sequential(nn.ConvTranspose2d(64, 1, 3, 1, 1), )\n",
    "        \n",
    "        self.maxunpool5 = nn.MaxUnpool2d(2,stride=2)\n",
    "        \n",
    "    def forward(self, x_in, indices):\n",
    "        \n",
    "        x = self.maxunpool1(x_in, indices[4])\n",
    "        x = self.convtrans1(x)\n",
    "        x = self.maxunpool2(x, indices[3])\n",
    "        x = self.convtrans2(x)\n",
    "        x = self.maxunpool3(x, indices[2])\n",
    "        x = self.convtrans3(x)\n",
    "        x = self.maxunpool4(x, indices[1])\n",
    "        x = self.convtrans4(x)\n",
    "        x = self.maxunpool5(x, indices[0])\n",
    "        x = self.convtrans5(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9de581fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Configuration parameter\n",
    "\n",
    "n_epoch = 20                # Number of epochs\n",
    "batch_size = 128            # Size of the batch\n",
    "learning_rate = 0.001       # learning rate for ADAM optimizer\n",
    "noise_std = 0.01            # \n",
    "DAE_fig_upd_period = 10     # Every this variable batches, we will be saving the accumulated loss wwithin the batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "710c8d88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read Meta data \n",
    "data_meta = pd.read_csv('../11-Video_Feature_Generation/output/scaled_objects/meta_data.csv')\n",
    "\n",
    "# Read Yolo Objects and create torch datasets\n",
    "ped_2_train = CustomDataset(only_train=True)\n",
    "train_loader = DataLoader(ped_2_train, batch_size = batch_size, shuffle=True)\n",
    "ped_2_all = CustomDataset(only_train=False)\n",
    "all_loader = DataLoader(ped_2_all, batch_size = batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ef8df1e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 20/20 [07:05<00:00, 21.25s/it]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create the Autoencoder\n",
    "encoder=Encoder().cuda()\n",
    "decoder=Decoder().cuda()\n",
    "\n",
    "# Loss functions and optimizers\n",
    "parameters=list(encoder.parameters())+list(decoder.parameters())\n",
    "loss_func=nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(parameters, lr=learning_rate, weight_decay=0.0001)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=25, gamma=0.6)\n",
    "    \n",
    "# Autoencoder training\n",
    "\n",
    "# Accumulators\n",
    "batch_count = 0\n",
    "running_loss = 0.0\n",
    "\n",
    "# Create performance save arrays\n",
    "xs = []\n",
    "ys = []\n",
    "\n",
    "for I in tqdm(range(n_epoch)):\n",
    "    \n",
    "    for image,label in train_loader:\n",
    "        \n",
    "        # create noise\n",
    "        noise=torch.tensor(np.random.normal(loc=0, scale=noise_std, size=image.shape)).type(torch.FloatTensor)\n",
    "        \n",
    "        # create noise image\n",
    "        image_n=torch.add(image, noise)\n",
    "        \n",
    "        # move images to GPU\n",
    "        image=Variable(image).cuda()\n",
    "        image_n=Variable(image_n).cuda()\n",
    "        \n",
    "        # run DAE\n",
    "        latent_features, indices = encoder(image_n)\n",
    "        output = decoder(latent_features, indices)\n",
    "        \n",
    "        # Get loss\n",
    "        loss = loss_func(output,image)\n",
    "        \n",
    "        # Learning\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        \n",
    "        # print progress\n",
    "        running_loss += loss.item()\n",
    "        if batch_count % DAE_fig_upd_period == DAE_fig_upd_period-1:    # every 1000 mini-batches...\n",
    "            xs.append(I * len(train_loader) + batch_count)\n",
    "            ys.append(running_loss)\n",
    "            running_loss = 0.0\n",
    "            \n",
    "        # print one pass\n",
    "        batch_count = batch_count+1\n",
    "        \n",
    "# create performance watch\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "ax.plot(xs,ys,'--*b')\n",
    "ax.set_xscale('log')\n",
    "ax.set_yscale('log')\n",
    "plt.xlabel('Number of mini batches')\n",
    "plt.ylabel('Running loss')\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "30d4aa2b",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 1 is out of bounds for dimension 0 with size 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\BASARB~1\\AppData\\Local\\Temp/ipykernel_12060/4256744686.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtest_image_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0minput_img\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mimage_n\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtest_image_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0moutput_img\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtest_image_index\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0morigin\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: index 1 is out of bounds for dimension 0 with size 1"
     ]
    }
   ],
   "source": [
    "# Test couple of examples\n",
    "test_image_index = 1\n",
    "img=image[test_image_index].cpu()\n",
    "input_img=image_n[test_image_index].cpu()\n",
    "output_img=output[test_image_index].cpu()\n",
    "\n",
    "origin=img.data.numpy()\n",
    "inp=input_img.data.numpy()\n",
    "out=output_img.data.numpy()\n",
    "\n",
    "f, axs = plt.subplots(1,3,figsize=(15,15))\n",
    "axs[0].imshow(origin[0],cmap='gray')\n",
    "axs[0].set_title('Original Image')\n",
    "\n",
    "axs[1].imshow(inp[0],cmap='gray')\n",
    "axs[1].set_title('Original Image + Gaussian Noise')\n",
    "\n",
    "axs[2].imshow(out[0],cmap='gray')\n",
    "axs[2].set_title('Reconstructed Noisy Image')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "430950df",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                        | 0/56119 [00:00<?, ?it/s]c:\\users\\basarbatu\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\torch\\_tensor.py:493: UserWarning: non-inplace resize is deprecated\n",
      "  warnings.warn(\"non-inplace resize is deprecated\")\n",
      "100%|███████████████████████████████████████████████████████████████████████████| 56119/56119 [04:07<00:00, 226.31it/s]\n"
     ]
    }
   ],
   "source": [
    "# project all available data to latent space\n",
    "\n",
    "n=len(ped_2_all)\n",
    "latents = np.zeros((n, 33))\n",
    "\n",
    "for i in tqdm(range(n)):\n",
    "    \n",
    "    # get the sample\n",
    "    sample, _ = ped_2_all[i]\n",
    "    sample = sample.cpu()\n",
    "    tmp = np.expand_dims(sample, axis=0)   \n",
    "    sample = torch.from_numpy(tmp)\n",
    "    sample = Variable(sample).cuda()\n",
    "    \n",
    "    # get latent features\n",
    "    latent_features, indices = encoder(sample)\n",
    "    \n",
    "    # get decoded image\n",
    "    output = decoder(latent_features, indices)\n",
    "    \n",
    "    # save features\n",
    "    z1 = latent_features.resize(1,32).cpu().detach().numpy()[0]\n",
    "    latents[i,0:32] = z1\n",
    "    \n",
    "    mse = torch.mean(torch.pow(torch.sub(sample, output), 2)).cpu().detach().numpy()\n",
    "    max_x = sample.max().cpu().detach().numpy()\n",
    "    z2 = 10*np.log10(max_x/mse) # PSNR\n",
    "    latents[i,32] = z2\n",
    "    \n",
    "# combine meta data and latent features\n",
    "latent_pd = pd.DataFrame(latents, columns=['dae_latent_feature_{:02d}'.format(x) for x in range(33)])\n",
    "latent_pd.rename(columns={'dae_latent_feature_32': 'spnr'}, inplace=True)\n",
    "ped2_df = pd.concat([data_meta,latent_pd], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "38840c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save output as mat to be used in matlab\n",
    "\n",
    "out_df = {name: col.values for name, col in ped2_df.items()}\n",
    "sio.savemat('./output/ped2.mat', out_df)\n",
    "sio.savemat('C:/Users/basarbatu/Desktop/phd/02-research/10-Video-NP/data/raw/ped2.mat', out_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
