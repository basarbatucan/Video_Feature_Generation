{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6b0780bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "344c14ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "\n",
    "data_path = './data/UCSD_Anomaly_Dataset.v1p2/UCSDped1/'\n",
    "output = './output/UCSDped1/'\n",
    "\n",
    "test_path = data_path + 'Test/'\n",
    "train_path = data_path + 'Train/'\n",
    "output_test_path = output + 'Test/'\n",
    "output_train_path = output + 'Train/'\n",
    "\n",
    "yolo_detection_conf = 0.4\n",
    "DAE_in_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6fda2865",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\basarbatu/.cache\\torch\\hub\\ultralytics_yolov5_master\n",
      "YOLOv5  2021-11-3 torch 1.10.0+cu113 CUDA:0 (NVIDIA GeForce RTX 2070 SUPER, 8192MiB)\n",
      "\n",
      "Fusing layers... \n",
      "Model Summary: 444 layers, 86705005 parameters, 0 gradients\n",
      "Adding AutoShape... \n"
     ]
    }
   ],
   "source": [
    "# load the model\n",
    "model = torch.hub.load('ultralytics/yolov5', 'yolov5x')\n",
    "\n",
    "# define confidence of the model\n",
    "model.conf = yolo_detection_conf\n",
    "\n",
    "# define classes to detect\n",
    "# select this list based on the objects that you want to detect\n",
    "\n",
    "# UCSD ped1 (refined for the objects of interest)\n",
    "model.classes = [0, 1, 2, 3, 7, 24, 26, 36]\n",
    "# UCSD ped2 (refined for the objects of interest)\n",
    "#model.classes = [0,1,7,36]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8c5f0be5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(158, 238, 3)\n"
     ]
    }
   ],
   "source": [
    "train_folders = [train_path+x for x in os.listdir(train_path) if os.path.isdir(os.path.join(train_path, x))]\n",
    "test_folders = [test_path+x for x in os.listdir(test_path) if os.path.isdir(os.path.join(test_path, x)) and x[-2:]!='gt']\n",
    "images = [x for x in os.listdir(train_folders[0]) if x[0]!='.']\n",
    "input_img_path = train_folders[0] + '/' + images[0]\n",
    "img = cv2.imread(input_img_path)\n",
    "print(img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "57b7adb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 34/34 [05:05<00:00,  8.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Object detection for training images completed...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "d = {'xmin': [], 'ymin': [], 'xmax': [], 'ymax': [], 'confidence':[], 'class':[], 'name':[], 'ori_im_path':[], 'scaled_im_path':[], 'label':[], 'frame_n':[], 'test_train':[]}\n",
    "data_meta = pd.DataFrame(data=d)\n",
    "\n",
    "frame_index = 0\n",
    "yolo_obj_index = 0\n",
    "\n",
    "# reading train images\n",
    "for fold in tqdm(train_folders):\n",
    "    images = [x for x in os.listdir(fold) if x[0]!='.']\n",
    "    for i in range(0, len(images)):\n",
    "        # read image\n",
    "        input_img_path = fold + '/' + images[i]\n",
    "        img = cv2.imread(input_img_path)\n",
    "        # make prediction\n",
    "        results = model(img)\n",
    "        out = results.pandas().xyxy[0]\n",
    "        # update common info\n",
    "        out['test_train'] = 'train'\n",
    "        out['frame_n'] = frame_index\n",
    "        out['ori_im_path'] = input_img_path\n",
    "        # append meta data\n",
    "        data_meta = data_meta.append(out, ignore_index=True)\n",
    "        # go through the all detections\n",
    "        for j in range(0, len(out)):\n",
    "            # get the cropped image\n",
    "            xmin = int(out.loc[j, 'xmin'])\n",
    "            xmax = int(out.loc[j, 'xmax'])\n",
    "            ymin = int(out.loc[j, 'ymin'])\n",
    "            ymax = int(out.loc[j, 'ymax'])\n",
    "            # extract image\n",
    "            yolo_object_img = img[ymin:ymax, xmin:xmax, :]\n",
    "            # rescale the cropped image\n",
    "            resized_yolo_object_img = cv2.resize(yolo_object_img, (DAE_in_size, DAE_in_size), interpolation = cv2.INTER_AREA)\n",
    "            # save the scaled images\n",
    "            saved_path = output_train_path + '{:06d}.png'.format(yolo_obj_index)\n",
    "            cv2.imwrite(saved_path, resized_yolo_object_img)\n",
    "            data_meta.loc[yolo_obj_index, 'scaled_im_path'] = saved_path\n",
    "            # update meta data for label\n",
    "            data_meta.loc[yolo_obj_index, 'label'] = 0\n",
    "            yolo_obj_index = yolo_obj_index+1\n",
    "        frame_index = frame_index+1\n",
    "        \n",
    "print('Object detection for training images completed...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b51d957f-21bf-410c-9654-c41479b0952a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b8c53423",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 36/36 [13:51<00:00, 23.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Object detection for test images completed...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# reading test images\n",
    "for fold in tqdm(test_folders):\n",
    "    images = [x for x in os.listdir(fold) if x[0]!='.']\n",
    "    for i in range(0, len(images)):\n",
    "        # read image\n",
    "        input_img_path = fold + '/' + images[i]\n",
    "        img = cv2.imread(input_img_path)\n",
    "        # read annot\n",
    "        input_annot_path = fold + '_gt/' + images[i].split('.')[0]+'.bmp'\n",
    "        label = cv2.imread(input_annot_path, cv2.COLOR_BGR2GRAY)\n",
    "        # for some cases in USCDped2, there label is starting with frame\n",
    "        if label is None:\n",
    "            input_annot_path = fold + '_gt/frame' + images[i].split('.')[0]+'.bmp'\n",
    "            label = cv2.imread(input_annot_path, cv2.COLOR_BGR2GRAY)\n",
    "        # for some cases there will not be ground truth\n",
    "        if label is None:\n",
    "            label = img[:,:,0]*0\n",
    "        # make prediction\n",
    "        results = model(img)\n",
    "        out = results.pandas().xyxy[0]\n",
    "        # update common info\n",
    "        out['test_train'] = 'test'\n",
    "        out['frame_n'] = frame_index\n",
    "        out['ori_im_path'] = input_img_path\n",
    "        # append meta data\n",
    "        data_meta = data_meta.append(out, ignore_index=True)\n",
    "        # go through the all detections\n",
    "        for j in range(0, len(out)):\n",
    "            # get the cropped image\n",
    "            xmin = int(out.loc[j, 'xmin'])\n",
    "            xmax = int(out.loc[j, 'xmax'])\n",
    "            ymin = int(out.loc[j, 'ymin'])\n",
    "            ymax = int(out.loc[j, 'ymax'])\n",
    "            # extract image\n",
    "            yolo_object_img = img[ymin:ymax, xmin:xmax, :]\n",
    "            yolo_object_label = label[ymin:ymax, xmin:xmax]\n",
    "            # rescale the cropped image\n",
    "            resized_yolo_object_img = cv2.resize(yolo_object_img, (DAE_in_size, DAE_in_size), interpolation = cv2.INTER_AREA)\n",
    "            # save the scaled images\n",
    "            saved_path = output_test_path + '{:06d}.png'.format(yolo_obj_index)\n",
    "            cv2.imwrite(saved_path, resized_yolo_object_img)\n",
    "            data_meta.loc[yolo_obj_index, 'scaled_im_path'] = saved_path\n",
    "            # update meta data for label\n",
    "            is_abnormal = np.sum(yolo_object_label/255)/(yolo_object_label.shape[0]*yolo_object_label.shape[1])\n",
    "            data_meta.loc[yolo_obj_index, 'label'] = is_abnormal\n",
    "            yolo_obj_index = yolo_obj_index+1\n",
    "        frame_index = frame_index+1\n",
    "        \n",
    "print('Object detection for test images completed...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "372f19f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the meta file\n",
    "data_meta.to_csv(output + 'meta_data.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
