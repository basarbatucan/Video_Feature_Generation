{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6b0780bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import torch\n",
    "import time\n",
    "import torch.backends.cudnn as cudnn\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "344c14ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "\n",
    "data_path = './data/UCSD_Anomaly_Dataset.v1p2/UCSDped2/'\n",
    "output = './output/UCSDped2/'\n",
    "\n",
    "test_path = data_path + 'Test/'\n",
    "train_path = data_path + 'Train/'\n",
    "output_test_path = output + 'Test/'\n",
    "output_train_path = output + 'Train/'\n",
    "\n",
    "DAE_in_size = 64\n",
    "min_box_size_ratio = 0.002\n",
    "valid_perc = 0.1\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6fda2865",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\basarbatu/.cache\\torch\\hub\\ultralytics_yolov5_master\n",
      "YOLOv5  2021-11-3 torch 1.10.0+cu113 CUDA:0 (NVIDIA GeForce RTX 2070 SUPER, 8192MiB)\n",
      "\n",
      "Fusing layers... \n",
      "Model Summary: 367 layers, 46533693 parameters, 0 gradients, 109.1 GFLOPs\n",
      "Adding AutoShape... \n"
     ]
    }
   ],
   "source": [
    "# load the model\n",
    "model = torch.hub.load('ultralytics/yolov5', 'yolov5l')\n",
    "\n",
    "# define confidence of the model\n",
    "model.conf = 0.3  # confidence threshold (0-1)\n",
    "model.iou = 0.5   # NMS IoU threshold (0-1)\n",
    "\n",
    "# define classes here\n",
    "model.classes = [0, 1, 2, 3, 5, 6, 7, 8, 14, 15, 16]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8c5f0be5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172.8\n"
     ]
    }
   ],
   "source": [
    "train_folders = [train_path+x for x in os.listdir(train_path) if os.path.isdir(os.path.join(train_path, x))]\n",
    "test_folders = [test_path+x for x in os.listdir(test_path) if os.path.isdir(os.path.join(test_path, x)) and x[-2:]!='gt']\n",
    "images = [x for x in os.listdir(train_folders[0]) if x[0]!='.']\n",
    "input_img_path = train_folders[0] + '/' + images[0]\n",
    "img = cv2.imread(input_img_path)\n",
    "min_box_size = img.shape[0]*img.shape[1]*min_box_size_ratio\n",
    "print(min_box_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "57b7adb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 16/16 [01:49<00:00,  6.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Object detection for training images completed...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "d = {'xmin': [], 'ymin': [], 'xmax': [], 'ymax': [], 'area': [], 'confidence':[], 'class':[], 'name':[], 'ori_im_path':[], 'scaled_im_path':[], 'label':[], 'frame_n':[], 'train_valid_test':[]}\n",
    "data_meta = pd.DataFrame(data=d)\n",
    "frame_index = 0\n",
    "yolo_obj_index = 0\n",
    "# reading train images\n",
    "for fold in tqdm(train_folders):\n",
    "    images = [x for x in os.listdir(fold) if x[0]!='.']\n",
    "    for i in range(0, len(images)):\n",
    "        # read image\n",
    "        input_img_path = fold + '/' + images[i]\n",
    "        img = cv2.imread(input_img_path)\n",
    "        # make prediction\n",
    "        results = model(img)\n",
    "        out = results.pandas().xyxy[0]\n",
    "        # calculate area\n",
    "        out['area'] = (out['xmax']-out['xmin'])*(out['ymax']-out['ymin'])\n",
    "        # update common info\n",
    "        out['train_valid_test'] = 'train'\n",
    "        out['frame_n'] = frame_index\n",
    "        out['ori_im_path'] = input_img_path\n",
    "        # append meta data\n",
    "        data_meta = data_meta.append(out, ignore_index=True)\n",
    "        # go through the all detections\n",
    "        for j in range(0, len(out)):\n",
    "            # get the cropped image\n",
    "            xmin = int(out.loc[j, 'xmin'])\n",
    "            xmax = int(out.loc[j, 'xmax'])\n",
    "            ymin = int(out.loc[j, 'ymin'])\n",
    "            ymax = int(out.loc[j, 'ymax'])\n",
    "            # extract image\n",
    "            yolo_object_img = img[ymin:ymax, xmin:xmax, :]\n",
    "            # rescale the cropped image\n",
    "            resized_yolo_object_img = cv2.resize(yolo_object_img, (DAE_in_size, DAE_in_size), interpolation = cv2.INTER_AREA)\n",
    "            # save the scaled images\n",
    "            saved_path = output_train_path + '{:06d}.png'.format(yolo_obj_index)\n",
    "            cv2.imwrite(saved_path, resized_yolo_object_img)\n",
    "            data_meta.loc[yolo_obj_index, 'scaled_im_path'] = saved_path\n",
    "            # update meta data for label\n",
    "            data_meta.loc[yolo_obj_index, 'label'] = 0\n",
    "            yolo_obj_index = yolo_obj_index+1\n",
    "        frame_index = frame_index+1\n",
    "print('Object detection for training images completed...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "124f5ff2-90ba-48df-9944-ed9350e8e22e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign last percentage of the training set as validation\n",
    "\n",
    "n_valid = round(len(data_meta)*valid_perc)\n",
    "valid_indices = data_meta.sample(n_valid).index\n",
    "data_meta.loc[valid_indices, 'train_valid_test'] = 'valid'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b8c53423",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 12/12 [01:56<00:00,  9.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Object detection for test images completed...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# reading test images\n",
    "for fold in tqdm(test_folders):\n",
    "    images = [x for x in os.listdir(fold) if x[0]!='.']\n",
    "    for i in range(0, len(images)):\n",
    "        # read image\n",
    "        input_img_path = fold + '/' + images[i]\n",
    "        img = cv2.imread(input_img_path)\n",
    "        # read annot\n",
    "        input_annot_path = fold + '_gt/' + images[i].split('.')[0]+'.bmp'\n",
    "        label = cv2.imread(input_annot_path, cv2.COLOR_BGR2GRAY)\n",
    "        # for some cases in USCDped2, there label is starting with frame\n",
    "        if label is None:\n",
    "            input_annot_path = fold + '_gt/frame' + images[i].split('.')[0]+'.bmp'\n",
    "            label = cv2.imread(input_annot_path, cv2.COLOR_BGR2GRAY)\n",
    "        # for some cases there will not be ground truth\n",
    "        if label is None:\n",
    "            label = img[:,:,0]*0\n",
    "        # make prediction\n",
    "        results = model(img)\n",
    "        out = results.pandas().xyxy[0]\n",
    "        # calculate area\n",
    "        out['area'] = (out['xmax']-out['xmin'])*(out['ymax']-out['ymin'])\n",
    "        # update common info\n",
    "        out['train_valid_test'] = 'test'\n",
    "        out['frame_n'] = frame_index\n",
    "        out['ori_im_path'] = input_img_path\n",
    "        # append meta data\n",
    "        data_meta = data_meta.append(out, ignore_index=True)\n",
    "        # go through the all detections\n",
    "        for j in range(0, len(out)):\n",
    "            # get the cropped image\n",
    "            xmin = int(out.loc[j, 'xmin'])\n",
    "            xmax = int(out.loc[j, 'xmax'])\n",
    "            ymin = int(out.loc[j, 'ymin'])\n",
    "            ymax = int(out.loc[j, 'ymax'])\n",
    "            # extract image\n",
    "            yolo_object_img = img[ymin:ymax, xmin:xmax, :]\n",
    "            yolo_object_label = label[ymin:ymax, xmin:xmax]\n",
    "            # rescale the cropped image\n",
    "            resized_yolo_object_img = cv2.resize(yolo_object_img, (DAE_in_size, DAE_in_size), interpolation = cv2.INTER_AREA)\n",
    "            # save the scaled images\n",
    "            saved_path = output_test_path + '{:06d}.png'.format(yolo_obj_index)\n",
    "            cv2.imwrite(saved_path, resized_yolo_object_img)\n",
    "            data_meta.loc[yolo_obj_index, 'scaled_im_path'] = saved_path\n",
    "            # update meta data for label\n",
    "            is_abnormal = np.sum(yolo_object_label/255)/(yolo_object_label.shape[0]*yolo_object_label.shape[1])\n",
    "            data_meta.loc[yolo_obj_index, 'label'] = is_abnormal\n",
    "            yolo_obj_index = yolo_obj_index+1\n",
    "        frame_index = frame_index+1\n",
    "print('Object detection for test images completed...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "484932bf-be39-4b6e-8deb-537187b519de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle train valid and test sets within their groups\n",
    "train_data = data_meta[data_meta['train_valid_test']=='train'].sample(frac=1)\n",
    "valid_data = data_meta[data_meta['train_valid_test']=='valid'].sample(frac=1)\n",
    "test_data = data_meta[data_meta['train_valid_test']=='test'].sample(frac=1)\n",
    "data_meta = pd.concat([train_data, valid_data, test_data], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "372f19f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total row number dropped from 60268 to 58456\n"
     ]
    }
   ],
   "source": [
    "# Exclude the small area yolo objects\n",
    "n1 = data_meta.shape[0]\n",
    "data_meta = data_meta[data_meta['area']>min_box_size]\n",
    "n2 = data_meta.shape[0]\n",
    "print('Total row number dropped from {} to {}'.format(n1,n2))\n",
    "# Save the meta file\n",
    "data_meta.to_csv(output + 'meta_data.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
